{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b4a55662c598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import itertools\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer, BertModel\n",
    "from transformers import ViltProcessor, ViltModel, ViltConfig\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import logging as transformers_logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "        format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "        datefmt='%m/%d/%Y %H:%M:%S',\n",
    "        level=logging.INFO)\n",
    "transformers_logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cl_evaluation.evaluate_cl_algorithm import forward_transfer_eval, catastrophic_forgetting_eval\n",
    "from configs.model_configs import model_configs\n",
    "from configs.task_configs import task_configs, SUPPORTED_VL_TASKS\n",
    "from configs.adapter_configs import ADAPTER_MAP\n",
    "from utils.seed_utils import set_seed\n",
    "\n",
    "class Args:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_workers = 0\n",
    "        self.batch_size = 32\n",
    "        self.mcl_data_dir = '/data/datasets/MCL/'\n",
    "        self.pretrained_model_name = 'dandelin/vilt-b32-mlm'\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vilt_processor = ViltProcessor.from_pretrained(args.pretrained_model_name)\n",
    "vilt = ViltModel.from_pretrained(args.pretrained_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.vilt_modeling import ViltContinualLearner, ViltEncoderWrapper\n",
    "\n",
    "ordered_cl_tasks = ['vqa', 'nlvr2', 'snli-ve']\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model_config = model_configs['vilt']\n",
    "encoder_dim = model_config['encoder_dim']\n",
    "visual_mode = model_config['visual_mode']\n",
    "batch2inputs_converter = model_config['batch2inputs_converter']\n",
    "\n",
    "encoder = ViltEncoderWrapper(vilt_processor, vilt, device)\n",
    "model = ViltContinualLearner(ordered_cl_tasks, encoder, encoder_dim, task_configs)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join('/data/experiments/MCL', 'vilt-sequential_ft-task0_vqa-task1_nlvr2-task2_snli-ve', \\\n",
    "                        'checkpoints', 'task1_nlvr2', 'model')\n",
    "model.load_state_dict(torch.load(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data.visionlanguage_datasets.nlvr2_dataset import build_nlvr2_dataloader\n",
    "\n",
    "nlvr_config = task_configs['nlvr2']\n",
    "data_dir = os.path.join(args.mcl_data_dir, nlvr_config['data_dir'])\n",
    "val_dataloader = build_nlvr2_dataloader(args=args,\n",
    "                                          data_dir=data_dir,\n",
    "                                          split='val',\n",
    "                                          visual_mode=visual_mode)\n",
    "model.eval()\n",
    "eval_score = 0\n",
    "t = tqdm(val_dataloader, desc='Evaluating on NLVR2 val set')\n",
    "total = 0\n",
    "for step, batch in enumerate(t):\n",
    "    inputs = batch2inputs_converter(batch)\n",
    "    with torch.no_grad():\n",
    "        output = model(task_key='nlvr2', **inputs)\n",
    "        logits = output[1]\n",
    "\n",
    "    batch_scores = (logits.argmax(-1).cpu() == batch['labels'])\n",
    "    eval_score += batch_scores.sum().item()\n",
    "    total += batch_scores.shape[0]\n",
    "    t.set_postfix({'score': eval_score/total})\n",
    "eval_score = eval_score/len(val_dataloader.dataset)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
